import requests
from bs4 import BeautifulSoup

BASE_URL = "https://www.freisinger-stadtwerke.de"
PAGE_URL = BASE_URL + "/de/Stadtbus-Parkhaeuser/Stadtbus/Fahrplaene-gueltig-ab-15.12.2024/"
TXT_FILE = "freising-bus-schedules.txt"

HEADERS = {
    "User-Agent": "Mozilla/5.0"
}

ICONS = {
    "Stadtbus": "ğŸš",
    "Innenstadtbusse": "ğŸšŒ",
    "Flughafenbus": "âœˆï¸",
    "RufTaxi": "ğŸš–",
    "ExpressBus": "ğŸš…",
    "VerstÃ¤rkerbus": "ğŸ”"
}

def fetch_links_by_category():
    response = requests.get(PAGE_URL, headers=HEADERS)
    response.raise_for_status()
    soup = BeautifulSoup(response.content, "html.parser")

    categories = {}
    current_category = None

    for element in soup.select("h3, li a"):
        if element.name == "h3":
            current_category = element.get_text(strip=True)
            if current_category not in categories:
                categories[current_category] = []
        elif element.name == "a" and element.get("href", "").endswith(".pdf") and current_category:
            title = element.get_text(strip=True)
            href = element["href"]
            full_url = href if href.startswith("http") else BASE_URL + href
            categories[current_category].append((title, full_url))

    return categories

def write_schedule_file(data):
    with open(TXT_FILE, "w", encoding="utf-8") as f:
        f.write("ğŸšŒ ĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Stadtbus Freising (Ñ 15.12.2024)\n")
        f.write("Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº: Ğ¾Ñ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ°Ğ¹Ñ‚ Stadtwerke Freising\n")
        f.write(PAGE_URL + "\n\n")

        for category, entries in data.items():
            icon = ICONS.get(category, "ğŸ“")
            f.write(f"### {icon} {category}\n\n")
            for title, url in entries:
                f.write(f"ğŸ“„ {title}\n")
                f.write(f"ğŸ”— {url}\n\n")

if __name__ == "__main__":
    links = fetch_links_by_category()
    write_schedule_file(links)
    print("âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾: Ñ„Ğ°Ğ¹Ğ» freising-bus-schedules.txt ÑĞ¾Ğ·Ğ´Ğ°Ğ½.")
