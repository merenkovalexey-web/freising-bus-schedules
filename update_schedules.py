import requests
from bs4 import BeautifulSoup
import os

# URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å PDF
BASE_URL = "https://www.freisinger-stadtwerke.de"
TARGET_PAGE = f"{BASE_URL}/de/Stadtbus-Parkhaeuser/Stadtbus/Fahrplaene-gueltig-ab-15.12.2024/"

# –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫
OUTPUT_FILE = "freising-bus-schedules.txt"

# –ó–∞–≥–æ–ª–æ–≤–æ–∫, —á—Ç–æ–±—ã –ø—Ä–∏—Ç–≤–æ—Ä–∏—Ç—å—Å—è –æ–±—ã—á–Ω—ã–º –±—Ä–∞—É–∑–µ—Ä–æ–º
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115 Safari/537.36"
}

def fetch_pdfs():
    print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π...")
    res = requests.get(TARGET_PAGE, headers=HEADERS)
    res.raise_for_status()

    soup = BeautifulSoup(res.text, "html.parser")
    pdf_links = []

    for link in soup.find_all("a", href=True):
        href = link["href"]
        if href.endswith(".pdf"):
            full_url = BASE_URL + href if href.startswith("/") else href
            pdf_links.append(full_url)

    return pdf_links

def save_to_file(links):
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º {len(links)} —Å—Å—ã–ª–æ–∫ –≤ —Ñ–∞–π–ª '{OUTPUT_FILE}'...")
    with open(OUTPUT_FILE, "w") as f:
        for url in links:
            f.write(url + "\n")
    print("‚úÖ –ì–æ—Ç–æ–≤–æ!")

def main():
    print("üöç –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π Stadtbus Freising...")
    links = fetch_pdfs()
    save_to_file(links)

if __name__ == "__main__":
    main()
